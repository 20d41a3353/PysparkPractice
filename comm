from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import DecimalType
from datetime import date, timedelta


def reconcile_balances():

    today = date.today()
    run_date_str = today.strftime('%Y-%m-%d')

    yesterday = today - timedelta(days=7)
    yesterday_str = yesterday.strftime('%Y-%m-%d')

    spark = (
        SparkSession.builder
        .appName("Optimized Balance Sheet Comparison")
        .config("spark.driver.extraClassPath", "/app/ojdbc8.jar")
        .config("spark.sql.adaptive.enabled", "true")
        .config("spark.sql.shuffle.partitions", "200")
        .config("spark.sql.broadcastTimeout", "600")
        .getOrCreate()
    )

    JDBC_URL = "jdbc:oracle:thin:@//10.177.103.192:1523/fincorepdb1"
    DB_USER = "fincore"
    DB_PASSWORD = "Password#1234"

    connection_properties = {
        "user": DB_USER,
        "password": DB_PASSWORD,
        "driver": "oracle.jdbc.driver.OracleDriver",
        "fetchsize": "5000"
    }

    # ----------------------------------------------------------
    # 1️⃣ READ DATA USING PARALLEL JDBC PARTITIONING
    # ----------------------------------------------------------
    print("Reading CBS and GL tables in parallel...")

    cbs_df = (
        spark.read.format("jdbc")
        .option("url", JDBC_URL)
        .option("dbtable", "CBS_BALANCE")
        .option("user", DB_USER)
        .option("password", DB_PASSWORD)
        .option("fetchsize", 5000)
        .option("numPartitions", 50)
        .option("partitionColumn", "BRANCH_CODE")
        .option("lowerBound", 1)
        .option("upperBound", 99999)
        .load()
        .filter(col("BALANCE_DATE") == yesterday_str)
        .select("BRANCH_CODE", "CURRENCY", "CGL", "BALANCE")
        .withColumnRenamed("BALANCE", "CBS_BALANCE")
        .persist()
    )

    gl_df = (
        spark.read.format("jdbc")
        .option("url", JDBC_URL)
        .option("dbtable", "GL_BALANCE")
        .option("user", DB_USER)
        .option("password", DB_PASSWORD)
        .option("fetchsize", 5000)
        .option("numPartitions", 50)
        .option("partitionColumn", "BRANCH_CODE")
        .option("lowerBound", 1)
        .option("upperBound", 99999)
        .load()
        .filter(col("BALANCE_DATE") == yesterday_str)
        .select("BRANCH_CODE", "CURRENCY", "CGL", "BALANCE")
        .withColumnRenamed("BALANCE", "GL_BALANCE")
        .persist()
    )

    # ----------------------------------------------------------
    # 2️⃣ JOIN & COMPUTE TODAY DIFFERENCES
    # ----------------------------------------------------------
    print("Performing join and computing differences...")

    joined_df = (
        cbs_df.join(gl_df, ["BRANCH_CODE", "CURRENCY", "CGL"], "inner")
        .withColumn(
            "DIFFERENCE_AMOUNT",
            (coalesce(col("CBS_BALANCE"), lit(0)) - coalesce(col("GL_BALANCE"), lit(0))).cast(DecimalType(20, 4))
        )
        .filter(col("DIFFERENCE_AMOUNT") != 0)
        .withColumn("RECON_RUN_DATE", current_timestamp())
        .persist()
    )

    # ----------------------------------------------------------
    # 3️⃣ HEAD LOGIC (optimized)
    # ----------------------------------------------------------
    print("Applying HEAD logic...")

    head_col = (
        when(col("BRANCH_CODE") == "01999", "CAO")
        .when(substring("CGL", 9, 1) == "9", "PROVISION")
        .when(substring("CGL", 1, 4) == "1204", "CASH")
        .when(substring("CGL", 1, 2) == "62", "AUCA")
        .when(substring("CGL", 1, 4) == "6363", "CTA 6363")
        .when((substring("CGL", 1, 1) == "4") & (substring("CGL", 1, 4) == "4363"), "CTA 4363")
        .when(substring("CGL", 1, 1) == "4", "CTA")
        .when(substring("CGL", 1, 1) == "6", "CTA")
        .when(substring("CGL", 1, 1) == "7", "I/E")
        .when(substring("CGL", 1, 1) == "8", "I/E")
        .when((substring("CGL", 1, 1) == "5") & (col("CURRENCY") == "INR"), "MEMO")
        .when((substring("CGL", 1, 1) == "5"), "FC MEMO")
        .when((substring("CGL", 1, 4) == "2148") & (col("CURRENCY") == "INR"), "BGL")
        .when(substring("CGL", 1, 4) == "2148", "FC")
        .when(substring("CGL", 1, 4) == "2249", "INCA")
        .when(col("CGL").isin("2111", "2115", "2060"), "PPF")
        .when(col("CGL") == "1000505003", "MIGRATION")
        .when(col("CGL") == "1100505001", "LHO")
        .when(substring("CGL", 1, 1) == "1", when(col("CURRENCY") == "INR", "LOAN").otherwise("FC"))
        .otherwise(when(col("CURRENCY") == "INR", "DEPOSITS").otherwise("FC"))
    )

    joined_df = joined_df.withColumn("HEAD", head_col)

    # ----------------------------------------------------------
    # 4️⃣ LOAD YESTERDAY’S STORED DATA (small table → broadcast)
    # ----------------------------------------------------------
    print("Reading yesterday data...")

    difference_df = (
        spark.read.format("jdbc")
        .option("url", JDBC_URL)
        .option("dbtable", "DIFFERENCE")
        .options(**connection_properties)
        .load()
        .filter(col("RECON_RUN_DATE").cast("date") == lit(run_date_str).cast("date"))
        .select(
            col("BRANCH_CODE").alias("Y_BRANCH"),
            col("CURRENCY").alias("Y_CURR"),
            col("CGL").alias("Y_CGL"),
            col("DIFFERENCE_AMOUNT").alias("YESTERDAY_DIFF")
        )
    )

    # Broadcast for speed
    difference_df = broadcast(difference_df)

    # ----------------------------------------------------------
    # 5️⃣ JOIN & FINAL CALCULATIONS
    # ----------------------------------------------------------
    print("Computing FINAL results...")

    final_df = (
        joined_df.join(
            difference_df,
            [col("BRANCH_CODE") == col("Y_BRANCH"),
             col("CURRENCY") == col("Y_CURR"),
             col("CGL") == col("Y_CGL")],
            "left"
        )
        .withColumn("TODAY_DIFF", col("DIFFERENCE_AMOUNT"))
        .withColumn(
            "DIFF_BW_YESTERDAY",
            (coalesce(col("DIFFERENCE_AMOUNT"), lit(0)) -
             coalesce(col("YESTERDAY_DIFF"), lit(0))).cast(DecimalType(20, 4))
        )
        .withColumn(
            "TYPE",
            when(col("YESTERDAY_DIFF").isNull(), "New Entry")
            .when(col("DIFF_BW_YESTERDAY") == 0, "Zero Difference")
            .otherwise("Diff change")
        )
        .select(
            "RECON_RUN_DATE", "BRANCH_CODE", "CURRENCY", "CGL",
            "CBS_BALANCE", "GL_BALANCE", "DIFFERENCE_AMOUNT",
            "DIFF_BW_YESTERDAY", "TYPE", "HEAD"
        )
    )

    final_df.show(50, truncate=False)

    # ----------------------------------------------------------
    # 6️⃣ WRITE BACK TO DB (high performance JDBC write)
    # ----------------------------------------------------------
    print("Writing results to Oracle...")

    (
        final_df.write
        .format("jdbc")
        .option("url", JDBC_URL)
        .option("dbtable", "DIFFERENCE")
        .option("user", DB_USER)
        .option("password", DB_PASSWORD)
        .option("batchsize", 5000)
        .option("numPartitions", 20)
        .option("isolationLevel", "NONE")
        .mode("append")
        .save()
    )

    spark.stop()


if __name__ == "__main__":
    reconcile_balances()
